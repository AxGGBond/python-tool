#!/usr/bin/env python3
"""
PDFæ ¼å¼æ°‘æ³•å…¸è§£æå™¨
æ”¯æŒè§£æPDFæ ¼å¼çš„æ°‘æ³•å…¸æ–‡ä»¶
"""
import openai
import json
import re
import time
import os
from typing import List, Dict, Any, Optional
import PyPDF2
import pdfplumber
from pathlib import Path

class PDFCivilCodeParser:
    """PDFæ ¼å¼æ°‘æ³•å…¸è§£æå™¨"""
    
    def __init__(self, api_key: str = None, model: str = "qwen-plus-latest"):
        """
        åˆå§‹åŒ–è§£æå™¨
        
        Args:
            api_key: OpenAI APIå¯†é’¥ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸ºqwen-plus-latest
        """
        self.api_key = api_key or "sk-a14dc6cb330d4061a8d4396461f166f1"
        self.model = model
        self.client = openai.OpenAI(
            api_key=self.api_key, 
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            timeout=60.0  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°60ç§’
        )
    
    def read_pdf_file(self, file_path: str, method: str = "pdfplumber") -> str:
        """
        è¯»å–PDFæ–‡ä»¶å†…å®¹
        
        Args:
            file_path: PDFæ–‡ä»¶è·¯å¾„
            method: è¯»å–æ–¹æ³•ï¼Œå¯é€‰ "pdfplumber" æˆ– "pypdf2"
            
        Returns:
            æ–‡æ¡£å†…å®¹å­—ç¬¦ä¸²
        """
        try:
            if method == "pdfplumber":
                return self._read_with_pdfplumber(file_path)
            elif method == "pypdf2":
                return self._read_with_pypdf2(file_path)
            else:
                raise ValueError("method must be 'pdfplumber' or 'pypdf2'")
        except FileNotFoundError:
            raise FileNotFoundError(f"æ–‡ä»¶ {file_path} ä¸å­˜åœ¨")
        except Exception as e:
            raise Exception(f"è¯»å–PDFæ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def _read_with_pdfplumber(self, file_path: str) -> str:
        """ä½¿ç”¨pdfplumberè¯»å–PDF"""
        full_text = []
        
        with pdfplumber.open(file_path) as pdf:
            print(f"PDFå…±æœ‰ {len(pdf.pages)} é¡µ")
            
            for page_num, page in enumerate(pdf.pages, 1):
                print(f"æ­£åœ¨è¯»å–ç¬¬ {page_num} é¡µ...")
                text = page.extract_text()
                if text:
                    full_text.append(text)
        
        return '\n'.join(full_text)
    
    def _read_with_pypdf2(self, file_path: str) -> str:
        """ä½¿ç”¨PyPDF2è¯»å–PDF"""
        full_text = []
        
        with open(file_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            print(f"PDFå…±æœ‰ {len(pdf_reader.pages)} é¡µ")
            
            for page_num, page in enumerate(pdf_reader.pages, 1):
                print(f"æ­£åœ¨è¯»å–ç¬¬ {page_num} é¡µ...")
                text = page.extract_text()
                if text:
                    full_text.append(text)
        
        return '\n'.join(full_text)
    
    def extract_articles_from_pdf(self, file_path: str, method: str = "pdfplumber") -> List[Dict[str, str]]:
        """
        ä»PDFæ–‡æ¡£ä¸­æå–æ¡æ¬¾
        
        Args:
            file_path: PDFæ–‡ä»¶è·¯å¾„
            method: è¯»å–æ–¹æ³•
            
        Returns:
            æ¡æ¬¾åˆ—è¡¨ï¼Œæ¯ä¸ªæ¡æ¬¾åŒ…å«æ ‡é¢˜å’Œå†…å®¹
        """
        try:
            # è¯»å–PDFå†…å®¹
            full_text = self.read_pdf_file(file_path, method)
            
            # å¤„ç†æ–‡æœ¬æ ¼å¼
            full_text = self._clean_pdf_text(full_text)
            
            # æå–æ¡æ¬¾
            articles = []
            current_article = {"title": "", "content": ""}
            
            lines = full_text.split('\n')
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ¡æ¬¾æ ‡é¢˜ï¼ˆåŒ…å«"ç¬¬"å’Œ"æ¡"ï¼‰
                if re.match(r'ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ\d]+æ¡', line):
                    # å¦‚æœå·²æœ‰å½“å‰æ¡æ¬¾ï¼Œå…ˆä¿å­˜
                    if current_article["title"]:
                        articles.append(current_article.copy())
                    
                    # å¼€å§‹æ–°æ¡æ¬¾
                    current_article = {"title": line, "content": ""}
                else:
                    # æ·»åŠ åˆ°å½“å‰æ¡æ¬¾å†…å®¹
                    if current_article["title"]:
                        if current_article["content"]:
                            current_article["content"] += "\n" + line
                        else:
                            current_article["content"] = line
            
            # æ·»åŠ æœ€åä¸€ä¸ªæ¡æ¬¾
            if current_article["title"]:
                articles.append(current_article)
            
            return articles
            
        except Exception as e:
            raise Exception(f"æå–æ¡æ¬¾æ—¶å‡ºé”™: {e}")
    
    def _clean_pdf_text(self, text: str) -> str:
        """
        æ¸…ç†PDFæ–‡æœ¬ï¼Œå¤„ç†å¸¸è§çš„æ ¼å¼é—®é¢˜
        
        Args:
            text: åŸå§‹PDFæ–‡æœ¬
            
        Returns:
            æ¸…ç†åçš„æ–‡æœ¬
        """
        # æ›¿æ¢å¸¸è§çš„PDFæ ¼å¼é—®é¢˜
        text = text.replace('\r\n', '\n')
        text = text.replace('\r', '\n')
        
        # å¤„ç†å¤šä½™çš„ç©ºæ ¼
        text = re.sub(r' +', ' ', text)
        
        # å¤„ç†æ¢è¡Œé—®é¢˜
        text = re.sub(r'\n+', '\n', text)
        
        # åœ¨æ¡æ¬¾å‰ç¡®ä¿æœ‰æ¢è¡Œ
        text = re.sub(r'(ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ\d]+æ¡)', r'\n\1', text)
        
        return text.strip()
    
    def split_articles_by_regex(self, text: str) -> List[str]:
        """
        ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²æ¡æ¬¾
        
        Args:
            text: æ–‡æ¡£æ–‡æœ¬
            
        Returns:
            åˆ†å‰²åçš„æ¡æ¬¾åˆ—è¡¨
        """
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ‰¾åˆ°æ‰€æœ‰"ç¬¬xxxæ¡"çš„ä½ç½®ï¼Œç„¶åè¿›è¡Œåˆ†å‰²
        articles = re.split(r'(?=ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ\d]+æ¡)', text)
        # ç§»é™¤å¯èƒ½å­˜åœ¨çš„ç©ºå­—ç¬¦ä¸²
        articles = [art for art in articles if art.strip()]
        return articles
    
    def parse_single_article(self, article_text: str, article_index: int) -> Dict[str, Any]:
        """
        è§£æå•ä¸ªæ¡æ¬¾
        
        Args:
            article_text: æ¡æ¬¾æ–‡æœ¬
            article_index: æ¡æ¬¾ç´¢å¼•
            
        Returns:
            è§£æç»“æœå­—å…¸
        """
system_prompt = """
ä½ æ˜¯ä¸€ä¸ªæ³•å¾‹æ–‡ä¹¦ä¿¡æ¯æŠ½å–åŠ©æ‰‹ã€‚
ä½ çš„ä»»åŠ¡æ˜¯ï¼šæ ¹æ®è¾“å…¥çš„æ³•å¾‹æ–‡ä»¶ç±»å‹ï¼Œæå–å…³é”®ä¿¡æ¯ï¼Œå¹¶è½¬æ¢ä¸ºç»“æ„åŒ– JSONã€‚

è¯·éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š

1. **è¯†åˆ«æ–‡ä»¶ç±»å‹**ï¼š
- å¦‚æœæ˜¯ **æ³•å¾‹ / æ³•è§„ / è§„ç« **ï¼Œé€šå¸¸åŒ…å«â€œç¬¬Xæ¡â€ï¼Œè¯·é€æ¡æŠ½å– â†’ ä½¿ç”¨ã€æ¡æ–‡å‹ JSON æ¨¡æ¿ã€‘ã€‚
- å¦‚æœæ˜¯ **é€šçŸ¥ / æŒ‡å¯¼æ„è§ / éƒ¨é—¨è§£é‡Š**ï¼Œé€šå¸¸æ˜¯æ•´ç¯‡æ–‡ä»¶ â†’ ä½¿ç”¨ã€æ–‡ä»¶å‹ JSON æ¨¡æ¿ã€‘ã€‚
- å¦‚æœæ˜¯ **å¸æ³•è§£é‡Š**ï¼Œå¯èƒ½é€æ¡ï¼Œä¹Ÿå¯èƒ½æ•´ç¯‡ â†’ å¦‚æœæœ‰â€œç¬¬Xæ¡â€åˆ™ç”¨ã€æ¡æ–‡å‹ JSON æ¨¡æ¿ã€‘ï¼Œå¦åˆ™ç”¨ã€æ–‡ä»¶å‹ JSON æ¨¡æ¿ã€‘ã€‚
- å¦‚æœæ˜¯ **åˆ¤ä¾‹ / è£åˆ¤æ–‡ä¹¦**ï¼Œè¯·æŠ½å–å½“äº‹äººã€æ¡ˆç”±ã€æ³•é™¢æ„è§ã€è£åˆ¤ç»“æœ â†’ ä½¿ç”¨ã€æ¡ˆä¾‹å‹ JSON æ¨¡æ¿ã€‘ã€‚

2. **è¾“å‡ºæ ¼å¼**ï¼š
- ä¸¥æ ¼è¾“å‡º JSONï¼ˆæ— å¤šä½™æ–‡å­—ï¼‰ã€‚
- å¦‚æœæœ‰å¤šæ¡ï¼ˆå¦‚å¤šä¸ªæ¡æ–‡ï¼‰ï¼Œè¯·æ”¾åœ¨ JSON æ•°ç»„ä¸­ã€‚
- å¦‚æœæ˜¯å•ç¯‡ï¼ˆå¦‚é€šçŸ¥/æ¡ˆä¾‹ï¼‰ï¼Œå¯ä»¥åªè¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ã€‚

3. **ç¼ºå¤±å­—æ®µ**è¯·å¡«å†™ `null`ï¼Œå­—æ®µå¿…é¡»é½å…¨ã€‚
4. `keywords` æå–è¯¥æ¡æ–‡ä¸­çš„å…³é”®æ³•å¾‹æœ¯è¯­ã€‚
5. `summary` ç”¨ä¸€å¥è¯æ€»ç»“æ¡æ–‡æ ¸å¿ƒè§„å®šã€‚
6. `related_articles` å¦‚æœæœ‰æåŠå…¶ä»–æ¡æ¬¾ï¼Œå°±åˆ—å‡ºæ¥ï¼Œå¦åˆ™ç©ºæ•°ç»„ã€‚
7. **æ¡æ–‡å†…å®¹**ï¼šæ¯ä¸€æ¡çš„â€œcontentâ€å¿…é¡»åŒ…å«ä»è¯¥â€œç¬¬Xæ¡â€å¼€å§‹ï¼Œç›´åˆ°ä¸‹ä¸€ä¸ªâ€œç¬¬Yæ¡â€ä¹‹å‰çš„æ‰€æœ‰æ–‡å­—ï¼ˆåŒ…æ‹¬æ¡æ¬¾å†…çš„æ®µè½ã€åˆ—ä¸¾ã€å‰æ¬¾/åæ¬¾ï¼‰ï¼Œä¸è¦é—æ¼æˆ–æˆªæ–­ã€‚
8.  *content* å†…å®¹è¦è·ŸåŸæ–‡ä¸€æ ·ï¼Œä¸èƒ½åŠ å…¥è‡ªå·±çš„ç†è§£ï¼Œç›´æ¥å¤åˆ¶åŸæ–‡å†…å®¹å³å¯ã€‚

---

### ã€æ¡æ–‡å‹ JSON æ¨¡æ¿ã€‘
```json
{
"law_name": "",
"article_number": "",
"chapter": "",
"content": "",
"summary": "",
"keywords": [],
"scope": "",
"penalty": null,
"exceptions": null,
"related_articles": [],
"effective_date": "",
"amendment_date": "",
"validity_status": "",
 "document_number": "",
"legal_level": "",
"source_url": "",
"tags": [],
"jurisdiction": ""
}
````

### ã€æ–‡ä»¶å‹ JSON æ¨¡æ¿ã€‘ï¼ˆé€šçŸ¥/è§£é‡Šç±»ï¼‰

```json
{
"law_name": "",
"document_type": "",
"document_number": "",
"issuing_body": "",
"issue_date": "",
"effective_date": "",
"amendment_date": null,
"legal_level": "",
"jurisdiction": "",
"content": "",
"summary": "",
"keywords": [],
"scope": "",
"penalty": null,
"exceptions": null,
"related_documents": [],
"source_url": "",
"tags": []
}
```

### ã€æ¡ˆä¾‹å‹ JSON æ¨¡æ¿ã€‘ï¼ˆåˆ¤ä¾‹/è£åˆ¤æ–‡ä¹¦ï¼‰

```json
{
"case_name": "",
"case_number": "",
"court": "",
"trial_date": "",
"document_type": "",
"legal_level": "è£åˆ¤æ–‡ä¹¦",
"jurisdiction": "",
"parties": {
"plaintiff": "",
"defendant": ""
},
"facts": "",
"claims": "",
"defenses": "",
"court_opinion": "",
"judgment": "",
"related_laws": [],
"summary": ""
}
```

---

### ç¤ºä¾‹è¾“å…¥ï¼ˆæ¡æ–‡å‹ï¼‰
```
ã€Šä¸­åäººæ°‘å…±å’Œå›½ä¼ä¸šæ‰€å¾—ç¨æ³•å®æ–½æ¡ä¾‹ã€‹
æ—¶ æ•ˆ æ€§ï¼šç°è¡Œæœ‰æ•ˆ
ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬512å·

ç¬¬äºŒç«  ç¨åŠ¡ç®¡ç†

ç¬¬å…­åæ¡ã€€é™¤å›½åŠ¡é™¢è´¢æ”¿ã€ç¨åŠ¡ä¸»ç®¡éƒ¨é—¨å¦æœ‰è§„å®šå¤–ï¼Œå›ºå®šèµ„äº§è®¡ç®—æŠ˜æ—§çš„æœ€ä½å¹´é™å¦‚ä¸‹ï¼š
ã€€ã€€ï¼ˆä¸€ï¼‰æˆ¿å±‹ã€å»ºç­‘ç‰©ï¼Œä¸º20å¹´ï¼›
ã€€ã€€ï¼ˆäºŒï¼‰é£æœºã€ç«è½¦ã€è½®èˆ¹ã€æœºå™¨ã€æœºæ¢°å’Œå…¶ä»–ç”Ÿäº§è®¾å¤‡ï¼Œä¸º10å¹´ï¼›
ã€€ã€€ï¼ˆä¸‰ï¼‰ä¸ç”Ÿäº§ç»è¥æ´»åŠ¨æœ‰å…³çš„å™¨å…·ã€å·¥å…·ã€å®¶å…·ç­‰ï¼Œä¸º5å¹´ï¼›
ã€€ã€€ï¼ˆå››ï¼‰é£æœºã€ç«è½¦ã€è½®èˆ¹ä»¥å¤–çš„è¿è¾“å·¥å…·ï¼Œä¸º4å¹´ï¼›
ã€€ã€€ï¼ˆäº”ï¼‰ç”µå­è®¾å¤‡ï¼Œä¸º3å¹´ã€‚

ç¬¬å…­åä¸€æ¡ã€€ä»äº‹å¼€é‡‡çŸ³æ²¹ã€å¤©ç„¶æ°”ç­‰çŸ¿äº§èµ„æºçš„ä¼ä¸šï¼Œåœ¨å¼€å§‹å•†ä¸šæ€§ç”Ÿäº§å‰å‘ç”Ÿçš„è´¹ç”¨å’Œæœ‰å…³å›ºå®šèµ„äº§çš„æŠ˜è€—ã€æŠ˜æ—§æ–¹æ³•ï¼Œç”±å›½åŠ¡é™¢è´¢æ”¿ã€ç¨åŠ¡ä¸»ç®¡éƒ¨é—¨å¦è¡Œè§„å®šã€‚

ç¬¬å…­åäºŒæ¡ã€€ç”Ÿäº§æ€§ç”Ÿç‰©èµ„äº§æŒ‰ç…§ä»¥ä¸‹æ–¹æ³•ç¡®å®šè®¡ç¨åŸºç¡€ï¼š
ã€€ã€€ï¼ˆä¸€ï¼‰å¤–è´­çš„ç”Ÿäº§æ€§ç”Ÿç‰©èµ„äº§ï¼Œä»¥è´­ä¹°ä»·æ¬¾å’Œæ”¯ä»˜çš„ç›¸å…³ç¨è´¹ä¸ºè®¡ç¨åŸºç¡€ï¼›
ã€€ã€€ï¼ˆäºŒï¼‰é€šè¿‡æèµ ã€æŠ•èµ„ã€éè´§å¸æ€§èµ„äº§äº¤æ¢ã€å€ºåŠ¡é‡ç»„ç­‰æ–¹å¼å–å¾—çš„ç”Ÿäº§æ€§ç”Ÿç‰©èµ„äº§ï¼Œä»¥è¯¥èµ„äº§çš„å…¬å…ä»·å€¼å’Œæ”¯ä»˜çš„ç›¸å…³ç¨è´¹ä¸ºè®¡ç¨åŸºç¡€ã€‚
ã€€ã€€å‰æ¬¾æ‰€ç§°ç”Ÿäº§æ€§ç”Ÿç‰©èµ„äº§ï¼Œæ˜¯æŒ‡ä¼ä¸šä¸ºç”Ÿäº§å†œäº§å“ã€æä¾›åŠ³åŠ¡æˆ–è€…å‡ºç§Ÿç­‰è€ŒæŒæœ‰çš„ç”Ÿç‰©èµ„äº§ï¼ŒåŒ…æ‹¬ç»æµæ—ã€è–ªç‚­æ—ã€äº§ç•œå’Œå½¹ç•œç­‰ã€‚

```

### ç¤ºä¾‹è¾“å‡º ï¼ˆæ¡æ–‡å‹ï¼‰

```json
[
  {
    "law_name": "ä¸­åäººæ°‘å…±å’Œå›½ä¼ä¸šæ‰€å¾—ç¨æ³•å®æ–½æ¡ä¾‹",
    "article_number": "ç¬¬å…­åæ¡",
    "chapter": null,
    "content": "é™¤å›½åŠ¡é™¢è´¢æ”¿ã€ç¨åŠ¡ä¸»ç®¡éƒ¨é—¨å¦æœ‰è§„å®šå¤–ï¼Œå›ºå®šèµ„äº§è®¡ç®—æŠ˜æ—§çš„æœ€ä½å¹´é™å¦‚ä¸‹ï¼š\nã€€ã€€ï¼ˆä¸€ï¼‰æˆ¿å±‹ã€å»ºç­‘ç‰©ï¼Œä¸º20å¹´ï¼›\nã€€ã€€ï¼ˆäºŒï¼‰é£æœºã€ç«è½¦ã€è½®èˆ¹ã€æœºå™¨ã€æœºæ¢°å’Œå…¶ä»–ç”Ÿäº§è®¾å¤‡ï¼Œä¸º10å¹´ï¼›\nã€€ã€€ï¼ˆä¸‰ï¼‰ä¸ç”Ÿäº§ç»è¥æ´»åŠ¨æœ‰å…³çš„å™¨å…·ã€å·¥å…·ã€å®¶å…·ç­‰ï¼Œä¸º5å¹´ï¼›\nã€€ã€€ï¼ˆå››ï¼‰é£æœºã€ç«è½¦ã€è½®èˆ¹ä»¥å¤–çš„è¿è¾“å·¥å…·ï¼Œä¸º4å¹´ï¼›\nã€€ã€€ï¼ˆäº”ï¼‰ç”µå­è®¾å¤‡ï¼Œä¸º3å¹´ã€‚",
    "summary": "è§„å®šå›ºå®šèµ„äº§æŠ˜æ—§çš„æœ€ä½å¹´é™ã€‚",
    "keywords": ["å›ºå®šèµ„äº§", "æŠ˜æ—§", "æœ€ä½å¹´é™"],
    "scope": "ä¼ä¸šçº³ç¨äºº",
    "penalty": null,
    "exceptions": null,
    "related_articles": ["ç¬¬å…­åæ¡"],
    "effective_date": null,
    "amendment_date": null,
   "document_number": "ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬512å·",
    "validity_status": "ç°è¡Œæœ‰æ•ˆ",
    "legal_level": "æ³•å¾‹",
    "source_url": "",
    "tags": ["å›ºå®šèµ„äº§", "æŠ˜æ—§"],
    "jurisdiction": "å…¨å›½"
  },
  {
    "law_name": "ä¸­åäººæ°‘å…±å’Œå›½ä¼ä¸šæ‰€å¾—ç¨æ³•å®æ–½æ¡ä¾‹",
    "article_number": "ç¬¬å…­åä¸€æ¡",
    "chapter": null,
    "content": "ä»äº‹å¼€é‡‡çŸ³æ²¹ã€å¤©ç„¶æ°”ç­‰çŸ¿äº§èµ„æºçš„ä¼ä¸šï¼Œåœ¨å¼€å§‹å•†ä¸šæ€§ç”Ÿäº§å‰å‘ç”Ÿçš„è´¹ç”¨å’Œæœ‰å…³å›ºå®šèµ„äº§çš„æŠ˜è€—ã€æŠ˜æ—§æ–¹æ³•ï¼Œç”±å›½åŠ¡é™¢è´¢æ”¿ã€ç¨åŠ¡ä¸»ç®¡éƒ¨é—¨å¦è¡Œè§„å®šã€‚",
    "summary": "æ˜ç¡®å¼€é‡‡çŸ³æ²¹ã€å¤©ç„¶æ°”ä¼ä¸šå›ºå®šèµ„äº§æŠ˜æ—§æ–¹æ³•ç”±å›½åŠ¡é™¢è§„å®šã€‚",
    "keywords": ["çŸ³æ²¹", "å¤©ç„¶æ°”", "çŸ¿äº§èµ„æº", "æŠ˜æ—§"],
    "scope": "å¼€é‡‡çŸ³æ²¹å¤©ç„¶æ°”ä¼ä¸š",
    "penalty": null,
    "exceptions": null,
    "related_articles": ["ç¬¬å…­åä¸€æ¡"],
    "effective_date": null,
    "amendment_date": null,
    "validity_status": "ç°è¡Œæœ‰æ•ˆ",
    "document_number": "ä¸­åäººæ°‘å…±å’Œå›½å›½åŠ¡é™¢ä»¤ ç¬¬512å·",
    "legal_level": "æ³•å¾‹",
    "source_url": "",
    "tags": ["çŸ¿äº§èµ„æº", "æŠ˜æ—§"],
    "jurisdiction": "å…¨å›½"
  }
]
```

"""

        # æ„å»ºä½ çš„ Promptï¼Œæ˜ç¡®æŒ‡ç¤ºè¾“å‡ºæ ¼å¼
        user_prompt = f"""
è¯·å°†ä»¥ä¸‹æ°‘æ³•å…¸æ¡æ¬¾å¤„ç†æˆ JSON æ ¼å¼ã€‚

æ¡æ¬¾æ–‡æœ¬ï¼š
{article_text}

è¯·ç›´æ¥è¾“å‡º JSONï¼Œä¸è¦æœ‰å…¶ä»–ä»»ä½•è§£é‡Šã€‚
"""

        try:
            # è°ƒç”¨ API
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0,
                response_format={"type": "json_object"}
            )

            # æå–æ¨¡å‹å›å¤
            model_response = response.choices[0].message.content
            print(f"  ğŸ¤– æ¨¡å‹å›å¤: {model_response}")

            # å°è¯•è§£æè¿”å›çš„ JSON
            json_output = json.loads(model_response)
            return json_output

        except json.JSONDecodeError as e:
            print(f"å¤„ç†ç¬¬ {article_index+1} æ¡æ—¶å‡ºé”™ï¼Œè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆ JSON: {model_response}")
            # å¯ä»¥é€‰æ‹©å°†é”™è¯¯å“åº”è®°å½•ä¸‹æ¥
            return {"error": f"Failed to parse JSON for article {article_index+1}", "raw_response": model_response}
        except Exception as e:
            print(f"å¤„ç†ç¬¬ {article_index+1} æ¡æ—¶å‘ç”Ÿå…¶ä»–é”™è¯¯: {e}")
            return {"error": f"Other error for article {article_index+1}"}
    
    def parse_pdf_civil_code(self, input_file: str, output_file: str = None, delay: float = 1.0, 
                           use_structured_extraction: bool = True, pdf_method: str = "pdfplumber") -> List[Dict[str, Any]]:
        """
        è§£æPDFæ ¼å¼çš„æ°‘æ³•å…¸
        
        Args:
            input_file: è¾“å…¥PDFæ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
            delay: APIè°ƒç”¨é—´éš”ï¼ˆç§’ï¼‰ï¼Œé¿å…é€Ÿç‡é™åˆ¶
            use_structured_extraction: æ˜¯å¦ä½¿ç”¨ç»“æ„åŒ–æå–ï¼ˆæ¨èï¼‰
            pdf_method: PDFè¯»å–æ–¹æ³•ï¼Œå¯é€‰ "pdfplumber" æˆ– "pypdf2"
            
        Returns:
            æ‰€æœ‰è§£æç»“æœçš„åˆ—è¡¨
        """
        if not output_file:
            input_path = Path(input_file)
            output_file = input_path.stem + "_parsed.json"
        
        print(f"å¼€å§‹è¯»å–PDFæ–‡æ¡£: {input_file}")
        
        if use_structured_extraction:
            # ä½¿ç”¨ç»“æ„åŒ–æå–æ–¹æ³•
            print("ä½¿ç”¨ç»“æ„åŒ–æå–æ–¹æ³•...")
            articles = self.extract_articles_from_pdf(input_file, pdf_method)
            print(f"å…±æ‰¾åˆ° {len(articles)} æ¡æ³•è§„")
            
            all_results = []
            for i, article in enumerate(articles):
                print(f"æ­£åœ¨å¤„ç†ç¬¬ {i+1} / {len(articles)} æ¡: {article['title']}")
                
                # ç»„åˆæ ‡é¢˜å’Œå†…å®¹
                full_text = f"{article['title']}\n{article['content']}"
                result = self.parse_single_article(full_text, i)
                all_results.append(result)
                
                # æ·»åŠ å»¶è¿Ÿ
                if delay > 0:
                    time.sleep(delay)
        else:
            # ä½¿ç”¨ä¼ ç»Ÿæ–‡æœ¬åˆ†å‰²æ–¹æ³•
            print("ä½¿ç”¨ä¼ ç»Ÿæ–‡æœ¬åˆ†å‰²æ–¹æ³•...")
            full_text = self.read_pdf_file(input_file, pdf_method)
            articles = self.split_articles_by_regex(full_text)
            print(f"å…±æ‰¾åˆ° {len(articles)} æ¡æ³•è§„")
            
            all_results = []
            for i, article_text in enumerate(articles):
                print(f"æ­£åœ¨å¤„ç†ç¬¬ {i+1} / {len(articles)} æ¡...")
                result = self.parse_single_article(article_text, i)
                all_results.append(result)
                
                # æ·»åŠ å»¶è¿Ÿ
                if delay > 0:
                    time.sleep(delay)
        
        # ä¿å­˜ç»“æœ
        print(f"æ­£åœ¨ä¿å­˜ç»“æœåˆ°: {output_file}")
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(all_results, f, ensure_ascii=False, indent=4)
        
        print(f"å¤„ç†å®Œæˆï¼å…±å¤„ç† {len(all_results)} æ¡æ³•è§„ã€‚ç»“æœå·²ä¿å­˜åˆ° {output_file}")
        return all_results
    
    def preview_pdf_content(self, file_path: str, max_articles: int = 5, pdf_method: str = "pdfplumber") -> None:
        """
        é¢„è§ˆPDFæ–‡æ¡£å†…å®¹
        
        Args:
            file_path: PDFæ–‡ä»¶è·¯å¾„
            max_articles: æœ€å¤§é¢„è§ˆæ¡æ¬¾æ•°
            pdf_method: PDFè¯»å–æ–¹æ³•
        """
        try:
            print(f"é¢„è§ˆPDFæ–‡æ¡£: {file_path}")
            print("=" * 50)
            
            # å°è¯•ç»“æ„åŒ–æå–
            articles = self.extract_articles_from_pdf(file_path, pdf_method)
            if articles:
                print(f"æ–‡æ¡£åŒ…å« {len(articles)} æ¡æ³•è§„")
                print("\nå‰å‡ æ¡æ³•è§„é¢„è§ˆ:")
                
                for i, article in enumerate(articles[:max_articles]):
                    print(f"\n{i+1}. {article['title']}")
                    content = article['content'][:100] + "..." if len(article['content']) > 100 else article['content']
                    print(f"   å†…å®¹: {content}")
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»“æ„åŒ–æ¡æ¬¾ï¼Œæ˜¾ç¤ºåŸå§‹æ–‡æœ¬
                text = self.read_pdf_file(file_path, pdf_method)
                print("æœªæ‰¾åˆ°ç»“æ„åŒ–æ¡æ¬¾ï¼Œæ˜¾ç¤ºåŸå§‹æ–‡æœ¬é¢„è§ˆ:")
                print(text[:500] + "..." if len(text) > 500 else text)
                
        except Exception as e:
            print(f"é¢„è§ˆæ–‡æ¡£æ—¶å‡ºé”™: {e}")


def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    # ä½¿ç”¨é…ç½®çš„APIå¯†é’¥
    api_key = "sk-a14dc6cb330d4061a8d4396461f166f1"  # è¯·æ›¿æ¢ä¸ºå®é™…çš„APIå¯†é’¥
    model = "qwen-plus-latest"
    base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
    
    print(f"âœ… ä½¿ç”¨é…ç½®çš„APIå¯†é’¥å’Œæ¨¡å‹: {model}")
    print(f"âœ… ä½¿ç”¨base_url: {base_url}")
    
    # åˆ›å»ºè§£æå™¨å®ä¾‹
    parser = PDFCivilCodeParser(api_key=api_key, model=model)
    
    # è¦è§£æçš„PDFæ–‡æ¡£
    input_file = "æ°‘æ³•å…¸.pdf"  # è¯·æ›¿æ¢ä¸ºå®é™…çš„PDFæ–‡ä»¶å
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_file):
        print(f"æ–‡ä»¶ {input_file} ä¸å­˜åœ¨")
        print("è¯·ç¡®ä¿PDFæ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸­")
        return
    
    # é¢„è§ˆæ–‡æ¡£å†…å®¹
    parser.preview_pdf_content(input_file)
    
    # è¯¢é—®æ˜¯å¦ç»§ç»­è§£æ
    response = input("\næ˜¯å¦ç»§ç»­è§£æï¼Ÿ(y/n): ")
    if response.lower() != 'y':
        print("è§£æå·²å–æ¶ˆ")
        return
    
    # è§£ææ°‘æ³•å…¸æ–‡ä»¶
    try:
        results = parser.parse_pdf_civil_code(
            input_file=input_file,
            output_file="æ°‘æ³•å…¸PDFè§£æç»“æœ.json",
            delay=1.0,  # æ¯æ¬¡APIè°ƒç”¨é—´éš”1ç§’
            use_structured_extraction=True,  # ä½¿ç”¨ç»“æ„åŒ–æå–
            pdf_method="pdfplumber"  # ä½¿ç”¨pdfplumberæ–¹æ³•
        )
        print(f"æˆåŠŸè§£æ {len(results)} æ¡æ³•è§„")
    except Exception as e:
        print(f"è§£æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")


if __name__ == "__main__":
    main()
